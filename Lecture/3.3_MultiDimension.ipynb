{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 다차원 배열의 계산\n",
    "\n",
    "넘파이의 다차원 배열을 사용한 계산법을 숙달하면 신경망을 효율적으로 구현할 수 있습니다.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 다차원 배열\n",
    "\n",
    "다차원 배열도 그 기본은 '숫자의 집합'입니다. 숫자가 한 줄로 늘어선 것이나 직사각형으로 늘어놓은 것, 3차원으로 늘어놓은 것이다 N차원으로 나열하는 것을 통틀어 다차원 배열이라고 합니다.<br/>\n",
    "<br/>\n",
    "우선은 지금까지 보아온 1차원 배열입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([1, 2, 3, 4])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[1,2], [3,4], [5,6]])\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2차원 배열은 행렬(matrix)이라고 부르고 [그림 3-10]과 같이 <br/>\n",
    "배열의 가로 방향을 행(row), 세로 방향을 열(column)이라고 합니다.<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "[그림 3-10] 2차원 배열(행렬)의 행(가로)과 열(세로)<br/>\n",
    "<img src=\"./imgs/3-10.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 행렬의 곱\n",
    "\n",
    "이어서 행렬의 곱을 구하는 방법을 알아보겠습니다. <br/>\n",
    "예를 들어 2 x 2 행렬의 곱은 [그림 3-11]처럼 계산합니다.<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "[그림 3-11] 행렬의 곱 계산 방법<br/>\n",
    "<img src=\"./imgs/3-11.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,2], [3,4]])\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[5,6], [7,8]])\n",
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 x 3 행렬과 3 x 2 행렬의 곱을 파이썬으로 구현한 모습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,2,3], [4,5,6]])\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[1,2], [3,4], [5,6]])\n",
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22, 28],\n",
       "       [49, 64]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다차원 배열을 곱하려면 두 행렬의 대응하는 차원의 원소 수를 일치시켜야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 신경망에서의 행렬 곱\n",
    "\n",
    "그럼 넘파이 행렬을 써서 신경망을 구현해보겟습니다. 이번 예에서는 [그림 3-14]의 간단한 신경망을 구현하는데,<br/>\n",
    "이 신경망은 편향과 활성화 함수를 생략하고 가중치만 갖습니다.<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "[그림 3-14] 행렬의 곱으로 신경망의 계산을 수행한다.<br/>\n",
    "<img src=\"./imgs/3-14.png\"><br/>\n",
    "<br/>\n",
    "특히 X와 W의 대응하는 차원의 원소 수가 같아야 한다는 걸 잊지 말아야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([1,2])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 5]\n",
      " [2 4 6]]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[1,3,5], [2,4,6]])\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 11 17]\n"
     ]
    }
   ],
   "source": [
    "Y = np.dot(X, W)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 신경망 구현하기\n",
    "\n",
    "이제 더 그럴싸한 신경망을 구현해보죠. 이번에는 [그림 3-15]의 순방향 처리(입력부터 출력까지의 처리)를 구현하겠습니다.<br/>\n",
    "이를 위해 앞에서 설명한 넘파이의 다차원 배열을 사용합니다. <br/>\n",
    "<br/>\n",
    "<br/>\n",
    "[그림 3-15] 순방향 처리 신경망 : 입력층은 2개, 첫 번째 은닉층은 3개, 두 번쨰 은닉층은 2개, 출력층은 2개의 뉴런으로 구성된다.<br/>\n",
    "<img src=\"./imgs/3-15.png\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 표기법 설명\n",
    "\n",
    "이번 절에서는 신경망에서의 처리를 설명하며 $w_{12}^{(1)}$과 $a_1^{(1)}$ 같은 표기법을 선보입니다.<br/>\n",
    "\n",
    "#### ( 조금 복잡해 보일 수 있지만, 이번 절에서만 사용하는 표기이니 가볍게 건너뛰고 읽어도 무방합니다!! )\n",
    "\n",
    "\n",
    "<br/>\n",
    "[그림 3-16] <br/>\n",
    "<img src=\"./imgs/3-16.png\" width=\"60%\" height=\"60%\"><br/>\n",
    "<br/>\n",
    "[그림 3-16]은 입력층의 뉴런 $x_2$에서 다음 층의 뉴런 $a_1^{(1)}$으로 향하는 선 위에 가중치를 표시하고 있습니다.<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[그림 3-16]의 가중치와 은닉층 뉴런의 오른쪽 위에는 $^{(1)}$이 붙어 있는데, 이는 1층의 가중치, 1층의 뉴런임을 뜻하는 번호입니다.<br/>\n",
    "또, 가중치 오른쪽 아래의 두 숫자는 차례로 다음 층 뉴런과 앞 층 뉴런의 인덱스 번호입니다.<br/>\n",
    "가령, $w_{12}^{(1)}$은 앞 층의 2번째 뉴런 ($x_2$)에서 다음 층의 1번째 뉴런($a_1^{(1)}$)으로 향할 때의 가중치라는 뜻입니다.<br/>\n",
    "<br/>\n",
    "가중치 오른쪽 아래의 인덱스 번호는 '다음 층 번호, 앞 층 번호'순으로 적습니다.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 각 층의 신호 전달 구현하기\n",
    "\n",
    "이번 절에서는 입력층에서 '1층의 첫 번째 뉴런'으로 가는 신호를 살펴보겠습니다.<br/>\n",
    "<br/>\n",
    "[그림 3-17] 입력층에서 1층으로 신호 전달 <br/>\n",
    "<img src=\"./imgs/3-17.png\" width=\"60%\" height=\"60%\"><br/>\n",
    "<br/>\n",
    "지금까지 확인한 것을 반영하여 $a_1^{(1)}$을 수식으로 나타내봅시다. $a_1^{(1)}$은 가중치를 곱한 신호 두 개와 편향을 합해서 다음과 같이 계산합니다.<br/>\n",
    "[식 3.8]<br/>\n",
    "$a_1^{(1)} = w_{11}^{(1)} x_1 + w_{12}^{(1)} x_2 + b_1^{(1)}$ <br/>\n",
    "<br/>\n",
    "여기서 행렬의 곱을 이용하면 1층의 '가중치 부분을 다음 식처럼 간소화할 수 있습니다.<br/>\n",
    "[식 3.9]<br/>\n",
    "$A^{(1)} = XW^{(1)} + B^{(1)}$ <br/>\n",
    "<br/>\n",
    "<br/>\n",
    "여기에서 행렬 $A^{(1)}, X, B^{(1)}, W^{(1)}$은 각각 다음과 같습니다.<br/>\n",
    "<br/>\n",
    "[식 3.8]<br/>\n",
    "$A ^{(1)} = (a_1^{(1)}, a_2^{(1)}, a_3^{(1)}),\\; X = (x_1, x_2),\\; B^{(1)} = (b_1^{(1)}\\, b_2^{(1)}\\, b_3^{(1)})$ <br/>\n",
    "<br/>\n",
    "[식 3.9]<br/>\n",
    "$\n",
    "W^{(1)} = \n",
    "\\begin{pmatrix}\n",
    "w_{11}^{(1)}&w_{21}^{(1)}&w_{31}^{(1)}\\\\\n",
    "w_{12}^{(1)}&w_{22}^{(1)}&w_{32}^{(1)}\\\\\n",
    "\\end{pmatrix}\n",
    "$<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "그럼 넘파이를 사용하여 [식 3.9]를 구현합시다. (입력 신호, 가중치, 편향은 적당한 값으로 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1.0, 0.5])\n",
    "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "B1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "print(W1.shape)  # (2, 3)\n",
    "print(X.shape)   # (2,)\n",
    "print(B1.shape)  # (3,)\n",
    "\n",
    "A1 = np.dot(X, W1) + B1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[그림 3-18] 입력층에서 1층으로의 신호 전달<br/>\n",
    "<img src=\"./imgs/3-18.png\" width=\"60%\" height=\"60%\"><br/>\n",
    "<br/>\n",
    "<br/>\n",
    "[그림 3-18]과 같이 은닉층에서의 가중치 합(가중 신호와 편향의 총합)을 $a$로 표기하고 <br/>\n",
    "활성화 함수 $h()$로 변환된 신호를 $z$로 표기합니다.<br/>\n",
    "<br/>\n",
    "여기에서는 활성화 함수로 시그모이드 함수를 사용하기로 합니다. 이를 파이썬으로 구현하면 다음과 같습니다.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 1.1]\n",
      "[0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "Z1 = sigmoid(A1)\n",
    "\n",
    "print(A1)  # [0.3 0.7 1.1]\n",
    "print(Z1)  # [0.57444252 0.66818777 0.75026011]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이어서 1층에서 2층으로 가는 과정(그림 3-19)과 그 구현을 살펴보죠.<br/>\n",
    "<br/>\n",
    "[그림 3-19]<br/>\n",
    "<img src=\"./imgs/3-19.png\" width=\"60%\" height=\"60%\"><br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 2)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "B2 = np.array([0.1, 0.2])\n",
    "\n",
    "print(Z1.shape)  # (3,)\n",
    "print(W2.shape)  # (3, 2)\n",
    "print(B2.shape)  # (2,)\n",
    "\n",
    "A2 = np.dot(Z1, W2) + B2\n",
    "Z2 = sigmoid(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
